{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ac5a75",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6ae050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 20:30:25.956910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171808d5",
   "metadata": {},
   "source": [
    "# 3X 1y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d956eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1215 = pd.read_feather('d1215.ftr', columns = None, use_threads = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34fa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084047, 823)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1215.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb856b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1215 = d1215.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bace3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_a2012 = 284412\n",
    "len_a2013 = 242826\n",
    "len_a2014 = 242448\n",
    "len_a2015 = 314361\n",
    "len_a2016 = 263593\n",
    "len_a2017 = 216591\n",
    "len_a2018 = 307395\n",
    "len_a2019 = 278610\n",
    "len_a2020 = 371006\n",
    "len_a2021 = 321808"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccbaa1",
   "metadata": {},
   "source": [
    "# df로 X,y train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1190ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1215.shape[0] == d1215.iloc[:-len_a2015,:-1].shape[0] + d1215.iloc[-len_a2015:,:-1].shape[0]\n",
    "X_train = d1215.iloc[:-len_a2015,2:-1]\n",
    "y_train = d1215.iloc[:-len_a2015,-1]\n",
    "X_test = d1215.iloc[-len_a2015:,2:-1]\n",
    "y_test = d1215.iloc[-len_a2015:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876690d",
   "metadata": {},
   "source": [
    "# 한 번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1dfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def my_regressor():\n",
    "#     X = d1215.iloc[:-len_a2015,2:-1] # 1214 데이터\n",
    "#     y = d1215.iloc[:-len_a2015,-1]\n",
    "    X = d1215.iloc[:,2:-1] # 1215 데이터\n",
    "    y = d1215.iloc[:,-1]\n",
    "    from sklearn.linear_model import LinearRegression # 일반 회귀 모델\n",
    "    from sklearn.linear_model import Ridge, Lasso, ElasticNet # Norm 규제 회귀 모델\n",
    "    from sklearn.linear_model import ARDRegression, BayesianRidge # 베이지안 회귀\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor # decision tree 앙상블 모델, 배깅\n",
    "    from xgboost import XGBRegressor # decision tree 앙상블 모델, 부스팅\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "#     from sklearn.model_selection import cross_val_score # model 검증\n",
    "    \n",
    "#     from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    from sklearn.dummy import DummyRegressor\n",
    "    from sklearn.metrics import mean_squared_error as mse # 모델 평가 지표 scoring (mse)\n",
    "    from sklearn.metrics import r2_score as r2\n",
    "    \n",
    "    import ast # convert string to function\n",
    "    \n",
    "    linear = LinearRegression()\n",
    "    ridge, lasso, elasticnet = Ridge(), Lasso(), ElasticNet()\n",
    "    ardr_linear, baysian_ridge = ARDRegression(), BayesianRidge()\n",
    "    DecisionTree = DecisionTreeRegressor(max_depth = 10)\n",
    "    random_forest = RandomForestRegressor(n_estimators=10,\n",
    "                                          n_jobs=16,\n",
    "                                          max_depth=10,\n",
    "                                          random_state=2,\n",
    "                                          verbose=2,\n",
    "                                          max_leaf_nodes=4)\n",
    "    xgboost_linear = XGBRegressor()\n",
    "    gbm = lgb.LGBMRegressor(num_leaves=31,\n",
    "                            learning_rate=0.05,\n",
    "                            n_estimators=20)\n",
    "\n",
    "    dummy = DummyRegressor(strategy = 'mean')\n",
    "    \n",
    "    my_model_list = ['linear', 'ridge', 'lasso', 'elasticnet',\n",
    "                     'ardr_linear', 'baysian_ridge',\n",
    "                     'xgboost_linear', 'gbm', 'dummy',\n",
    "                     'DecisionTree', 'random_forest'] # 오래 걸리는건 뒤로 뺌\n",
    "    \n",
    "    # seed 고정\n",
    "    user_seed = 0\n",
    "    random.seed(user_seed) # seed 고정\n",
    "    \n",
    "    # train끼리 idx 같아야 하므로\n",
    "    len_train = len_a2012+len_a2013+len_a2014\n",
    "    train_idx = list(range(len_train))\n",
    "    random.shuffle(train_idx) # 자동으로 덮어쓰기\n",
    "    \n",
    "    len_test = len_train + len_a2015\n",
    "    test_idx = list(range(len_train,len_test)) # +1 안해줘도 되는 거 위 cell에서 확인\n",
    "    random.shuffle(test_idx) # 자동으로 덮어쓰기\n",
    "    \n",
    "    i = 0\n",
    "    ######################################################################### fitting\n",
    "    for model_nm in tqdm(my_model_list):\n",
    "        ############################################################\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "#         X_train = (X.iloc[:-len_a2015,:]).sample(frac=1, random_state = user_seed)\n",
    "#         y_train = (y.iloc[:-len_a2015,:]).sample(frac=1, random_state = user_seed)\n",
    "#         X_test = (X.iloc[-len_a2015:,:]).sample(frac=1, random_state = user_seed)\n",
    "#         y_test = (y.iloc[-len_a2015:,:]).sample(frac=1, random_state = user_seed)\n",
    "        ############################################################\n",
    "        y_train = np.array(y_train).reshape(-1,1) # 1열짜리로 만드는 것\n",
    "        y_test = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "        ########################################################\n",
    "\n",
    "        # fitting\n",
    "        if model_nm == 'gbm':\n",
    "            model_ = eval(model_nm).fit(X_train, y_train,\n",
    "                                        eval_set=[(X_test, y_test)],\n",
    "                                        eval_metric='l1',\n",
    "                                        early_stopping_rounds=5)\n",
    "            y_pred_test = model_.predict(X_test, num_iteration=gbm.best_iteration_) # 예측\n",
    "\n",
    "        else:\n",
    "            model_ = eval(model_nm).fit(X_train, y_train)\n",
    "            y_pred_test = model_.predict(X_test) # 예측\n",
    "\n",
    "        mse_score = mse(y_test, y_pred_test)\n",
    "        r2_score = r2(y_test, y_pred_test)\n",
    "        # cv_scores = cross_val_score(eval(model_nm), X, y, cv=ss)\n",
    "\n",
    "        results.append([i, f'{model_nm}', mse_score, r2_score]) #[:str(model).index(\"(\")]\n",
    "        i+=1\n",
    "        \n",
    "#         # cv (안함)\n",
    "#         ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "#         for train_idx, test_idx in tqdm(ss.split(X,y)):\n",
    "#             x_train = d1215.iloc[train_idx,2:-1] # 식별변수 제외 나머지 열 ~ NC열 전까지\n",
    "#             y_train = d1215.iloc[train_idx,-1]\n",
    "#             x_test = d1215.iloc[test_idx,2:-1] # 식별변수 제외 나머지 열 ~ NC열 전까지\n",
    "#             y_test = d1215.iloc[test_idx,-1]\n",
    "            \n",
    "            \n",
    "#             y_train = np.array(y_train).reshape(-1,1) # 1열짜리로 만드는 것\n",
    "#             y_test = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "#             ########################################################\n",
    "        \n",
    "#             # fitting\n",
    "#             if model_nm == 'gbm':\n",
    "#                 model_ = eval(model_nm).fit(X_train, y_train,\n",
    "#                                             eval_set=[(X_test, y_test)],\n",
    "#                                             eval_metric='l1',\n",
    "#                                             early_stopping_rounds=5)\n",
    "#                 y_pred_test = model_.predict(x_test, num_iteration=gbm.best_iteration_) # 예측\n",
    "                \n",
    "#             else:\n",
    "#                 model_ = eval(model_nm).fit(x_train, y_train)\n",
    "#                 y_pred_test = model_.predict(x_test) # 예측\n",
    "\n",
    "#             mse_score = mse(y_test, y_pred_test)\n",
    "#             r2_score = r2(y_test, y_pred_test)\n",
    "#             # cv_scores = cross_val_score(eval(model_nm), X, y, cv=ss)\n",
    "\n",
    "#             results.append([i, f'{model_nm}', mse_score, r2_score]) #[:str(model).index(\"(\")]\n",
    "#             i+=1\n",
    "#             #####################################################################################\n",
    "        print(results[-5:])\n",
    "    return results#score_dic#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "_ = my_regressor()\n",
    "results\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472be75",
   "metadata": {},
   "source": [
    "Tree기반 너무 오래 걸림... max_depth, n_jobs 같은거 설정해야할듯 <br>\n",
    "00:23 <br>\n",
    "01:10 <br>\n",
    "02:00 <br>\n",
    "02:45 <br>\n",
    "\n",
    "[random forest hyperparameter tuning](https://velog.io/@emseoyk/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D) <br>\n",
    "\n",
    "- 지금은 1214로 train test shuffle split해서 모델링 하는 중.\n",
    "- 만약 15를 test로 하고싶다면 shuffle split은 포기해야함.\n",
    "- 그렇다면 df자체적으로 뒤섞는걸 하면 되려나?\n",
    "- 학습 순서가 의미 있을지도 모르니까. (전에 학습하는 순서 의미 있다는걸 듣긴 했음.)\n",
    "\n",
    "- df row 순서 섞는거는 0(처음)부터 2014년도의 마지막 데이터가 있는 행까지를 섞어서 인덱스를 다시 붙여주면 됨. (뭔 소리 하고있는건지 모르겠지만 아무튼 그렇다...)\n",
    "\n",
    "- df.sample(frac=1, random_state = 1)로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53067bcc",
   "metadata": {},
   "source": [
    "# plot을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b591239",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in results:\n",
    "    if i[1] not in dic: # dic.keys()라고 써도 됨.\n",
    "        dic[i[1]] = [i[2]]\n",
    "    else:\n",
    "        dic[i[1]].append(i[2])\n",
    "\n",
    "\n",
    "# import math\n",
    "# 리스트에 mean 함수가 내장이 안돼있다니...\n",
    "\n",
    "for i in dic.keys():\n",
    "    dic[i] = sum(dic[i])/len(dic[i])\n",
    "\n",
    "\n",
    "score_lst = sorted(dic.items(), key = lambda t : t[1]) #mse 작은 순으로 줄 세워짐.\n",
    "score_lst\n",
    "# dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dic = {}\n",
    "for i in score_lst:\n",
    "    score_dic[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(score_dic.items(), columns=['key', 'value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.key=='dummy']['value'].values\n",
    "f'dummy\\n: {dummy_mean[0]:.2f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e36424",
   "metadata": {},
   "source": [
    "# MSE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = 'key', y = 'value', data=df, capsize=.2)\n",
    "_ = g.set_xticks(range(len(df)))\n",
    "_ = g.set_xticklabels(g.get_xticklabels(), rotation=45)\n",
    "_ = g.set_xlabel(\"regression models\", fontsize = 15)\n",
    "_ = g.set_ylabel(\"Mean Squared Errors\", fontsize = 15)\n",
    "_ = g.set_ylim([0, 0.0155]) # ax.set(ylim=(0.4, 0.6))\n",
    "dummy_mean = df[df.key=='dummy']['value'].values\n",
    "_ = g.plot([-1,len(df)], [dummy_mean, dummy_mean], color = 'red')\n",
    "_ = g.annotate(text = f'dummy\\n: {dummy_mean[0]:.4f}', xy = (3, dummy_mean), xytext = (0.1, 0.0115),\n",
    "               arrowprops = dict(facecolor = 'red', shrink = 0),)\n",
    "\n",
    "\n",
    "val = df['value']\n",
    "cnt = 0\n",
    "for i in range(len(df)):\n",
    "    _ = g.text(cnt-0.27, 0.0007, f'{val[i]:.2f}')\n",
    "    cnt += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bc7ae",
   "metadata": {},
   "source": [
    "# ROC - AUC plot..? 은 분류에서...\n",
    "[ROC-AUC 공식문서](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91254aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0186112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
